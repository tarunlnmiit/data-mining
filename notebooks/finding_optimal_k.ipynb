{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A popular approach of determining the correct number of clusters K in a dataset is executing the clustering algorithm multiple times, each time with a different K, and then selecting the K that yields the optimal value for the chosen internal validation index. \n",
    "\n",
    "# Consider the 2 artificial datasets below that aim to determine the correct number of clusters.\n",
    "\n",
    "![circular_data](img/circular_data.png)\n",
    "![contiguous_data](img/contiguous_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the datasets and observe the correct number of clusters, indicated by the pointsâ€™ labels\n",
    "\n",
    "There are 5 clusters in the 1st dataset, and 3 clusters in the 2nd. However, most real world data is not 2-dimensional, so it will not be easy to determine the correct number of clusters.\n",
    "\n",
    "We will use **Silhouette Coefficient**, an internal cluster validation measure, to help estimate the correct number of clusters.\n",
    "\n",
    "Since there are circular clusters in the 1st dataset, a suitable clustering algorithm is K-Means. We run K-Means multiple times with different values of K and get the corresponding silhouette score, and the value of K that corresponds with the highest score is likely to be the correct number of clusters.\n",
    "\n",
    "![sil_circular](img/sil_circular.png)\n",
    "\n",
    "**The K with the highest silhouette score is 5, which makes sense as there are in fact 5 natural clusters in the 1st dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 2nd dataset, there are thin contiguous clusters, so K-Means will not work. DBSCAN or HAC with single-linkage are suitable methods for this type of data. We will use HAC single linkage.\n",
    "\n",
    "The silhouette scores for the different values of K are:\n",
    "\n",
    "| K  | Silhouette |\n",
    "| ---| ---------- |\n",
    "| 2  | 0.16 |\n",
    "| 3  | 0.0  |\n",
    "| 4  | 0.03 |\n",
    "| 5  | 0.1  |\n",
    "| 6  | 0.08 |\n",
    "| 7  | 0.06 |\n",
    "\n",
    "If we look at the silhouette plot for K = 3, the scores for most of the data points are negative\n",
    "\n",
    "![sil_plot](img/sil_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the problem of using the Silhouette Coefficient for the 2nd dataset? Which clustering families is this internal index most suited for/does not work well on.\n",
    "\n",
    "Let's recap how silhouette coefficient works. For a datapoint x, the silhouette score is 1 minus the following ratio: \n",
    "\n",
    "(average distance to points in the same cluster (a)) : (average distance distance to points in the nearest cluster (b))\n",
    "\n",
    "Silhouette score is high when a is small and b is large, and it is low when a is small and b is large\n",
    "\n",
    "This idea does not make sense in the following situation (blue lines are the distances to the points in the same cluster, and the red lines are the distances to points in the other cluster)\n",
    "\n",
    "![contiguous_clusters](img/contiguous_clusters.png)\n",
    "\n",
    "**In this data, even though the clusters have been correctly identified by single-link HAC, the silhouette score is low, since the structure of the clusters does not align with how silhouette coefficient gets maximized. Therefore silhouette coefficient is not suitable for datasets with clusters of arbitrary shapes. It is most suited for spherical clusters, so it is more applicable for k-means, complete linkage and Ward's method, but not for single linkage and DBSCAN since these methods tend to produce arbitarily shaped clusters.  It punishes clusters where the points are more far away to their cluster peers than they are to objects from different clusters with respect to Euclidean distance. Obviously, it doesn't take the \"U-shape-connection\" of the three clusters into account.**\n",
    "\n",
    "**So we should always think about which combination of clustering algorithm and evaluation index is correct for the shape of clusters we think are present in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
